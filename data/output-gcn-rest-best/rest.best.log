add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
add rest, sentiment: 0========
03/27/2024 10:29:01 - INFO - datasets -   Total sentiment counter: defaultdict(<class 'int'>, {'negative': 805, 'positive': 2164, 'neut
ral': 633})
03/27/2024 10:29:01 - INFO - datasets -   Multi-Aspect-Multi-Sentiment counter: defaultdict(<class 'int'>, {'positive': 351, 'neutral':
 288, 'negative': 301})
sentiment_counter: defaultdict(<class 'int'>, {0: 1610, 1: 2164, 2: 633})
03/27/2024 10:29:01 - INFO - datasets -   *** Start processing data(unrolling and reshaping) ***
03/27/2024 10:29:01 - INFO - datasets -   Total sentiment counter: defaultdict(<class 'int'>, {'positive': 728, 'neutral': 196, 'negati
ve': 196})
03/27/2024 10:29:01 - INFO - datasets -   Multi-Aspect-Multi-Sentiment counter: defaultdict(<class 'int'>, {'positive': 85, 'neutral':
83, 'negative': 60})
sentiment_counter: defaultdict(<class 'int'>, {1: 728, 2: 196, 0: 196})
03/27/2024 10:29:01 - INFO - datasets -   ****** After unrolling ******
03/27/2024 10:29:01 - INFO - datasets -   Train set size: 4407
03/27/2024 10:29:01 - INFO - datasets -   Test set size: 1120,
03/27/2024 10:29:01 - INFO - datasets -   Creating vocab of dependency tags.
03/27/2024 10:29:01 - INFO - datasets -   Saving dependency tags  vocab, size: 46, to file data/output-gcn-rest-final4_b/pkls/cached_re
st_dep_tag_vocab.pkl
03/27/2024 10:29:01 - INFO - datasets -   Creating vocab of dependency tags.
03/27/2024 10:29:01 - INFO - datasets -   Saving dependency tags  vocab, size: 46, to file data/output-gcn-rest-final4_b/pkls/cached_re
st_pos_tag_vocab.pkl
Some weights of the model checkpoint at /nas2/archived/qsj/bert-model/bert-base-uncased were not used when initializing BertModel: ['cl
s.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.tran
sform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relat
ionship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architectur
e (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initia
lizing a BertForSequenceClassification model from a BertForSequenceClassification model).
/nas2/lishengping/miniconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW
is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation
_warning=True` to disable this warning
  warnings.warn(
03/27/2024 10:29:14 - INFO - trainer -   ***** Running training *****
03/27/2024 10:29:14 - INFO - trainer -     Num examples = 4407
03/27/2024 10:29:14 - INFO - trainer -     Num Epochs = 30
03/27/2024 10:29:14 - INFO - trainer -     Instantaneous batch size per GPU = 16
03/27/2024 10:29:14 - INFO - trainer -     Gradient Accumulation steps = 2
03/27/2024 10:29:14 - INFO - trainer -     Total optimization steps = 4140
Epoch:   0%|                                                                                                    | 0/30 [00:00<?, ?it/s]
03/27/2024 10:29:22 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:29:22 - INFO - trainer -     Num examples = 1120
03/27/2024 10:29:22 - INFO - trainer -     Batch size = 32
/nas2/lishengping/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill
-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/nas2/lishengping/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill
-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/nas2/lishengping/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill
-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
              precision    recall  f1-score   support

  negativate     0.7653    0.6276    0.6897       239
  positivate     0.9615    0.7946    0.8701       881
     neutral     0.0000    0.0000    0.0000         0

    accuracy                         0.7589      1120
   macro avg     0.5756    0.4741    0.5199      1120
weighted avg     0.9197    0.7589    0.8316      1120

03/27/2024 10:29:23 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:29:23 - INFO - trainer -     eval loss: 0.6943765976599284
03/27/2024 10:29:23 - INFO - trainer -     acc = 0.7589285714285714
03/27/2024 10:29:23 - INFO - trainer -     f1 = 0.5199202760335183
03/27/2024 10:29:31 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:29:31 - INFO - trainer -     Num examples = 1120
03/27/2024 10:29:31 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.9388    0.5169    0.6667       356
  positivate     0.8805    0.8686    0.8745       738
     neutral     0.1173    0.8846    0.2072        26

    accuracy                         0.7571      1120
   macro avg     0.6455    0.7567    0.5828      1120
weighted avg     0.8813    0.7571    0.7929      1120

03/27/2024 10:29:32 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:29:32 - INFO - trainer -     eval loss: 0.5836536354252271
03/27/2024 10:29:32 - INFO - trainer -     acc = 0.7571428571428571
03/27/2024 10:29:32 - INFO - trainer -     f1 = 0.5827874258979308
Epoch:   3%|███                                                                                         | 1/30 [00:24<11:40, 24.15s/it]
03/27/2024 10:29:40 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:29:40 - INFO - trainer -     Num examples = 1120
03/27/2024 10:29:40 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.9490    0.5849    0.7237       318
  positivate     0.9135    0.8914    0.9023       746
     neutral     0.2551    0.8929    0.3968        56

    accuracy                         0.8045      1120
   macro avg     0.7058    0.7897    0.6743      1120
weighted avg     0.8906    0.8045    0.8263      1120

03/27/2024 10:29:41 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:29:41 - INFO - trainer -     eval loss: 0.5463224617498261
03/27/2024 10:29:41 - INFO - trainer -     acc = 0.8044642857142857
03/27/2024 10:29:41 - INFO - trainer -     f1 = 0.6742891513203378
03/27/2024 10:29:50 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:29:50 - INFO - trainer -     Num examples = 1120
03/27/2024 10:29:50 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8673    0.6911    0.7692       246
  positivate     0.9602    0.8545    0.9043       818
     neutral     0.2347    0.8214    0.3651        56

    accuracy                         0.8170      1120
   macro avg     0.6874    0.7890    0.6795      1120
weighted avg     0.9035    0.8170    0.8476      1120

03/27/2024 10:29:52 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:29:52 - INFO - trainer -     eval loss: 0.5433444027389799
03/27/2024 10:29:52 - INFO - trainer -     acc = 0.8169642857142857
03/27/2024 10:29:52 - INFO - trainer -     f1 = 0.6795264052702604
03/27/2024 10:30:00 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:30:00 - INFO - trainer -     Num examples = 1120
03/27/2024 10:30:00 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8418    0.6992    0.7639       236
  positivate     0.9451    0.8798    0.9113       782
     neutral     0.3622    0.6961    0.4765       102

    accuracy                         0.8250      1120
   macro avg     0.7164    0.7583    0.7172      1120
weighted avg     0.8702    0.8250    0.8406      1120

03/27/2024 10:30:02 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:30:02 - INFO - trainer -     eval loss: 0.4796508476138115
03/27/2024 10:30:02 - INFO - trainer -     acc = 0.825
03/27/2024 10:30:02 - INFO - trainer -     f1 = 0.7172190780495594
Epoch:   7%|██████▏                                                                                     | 2/30 [00:52<12:31, 26.84s/it]
03/27/2024 10:30:11 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:30:11 - INFO - trainer -     Num examples = 1120
03/27/2024 10:30:11 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7602    0.8187    0.7884       182
  positivate     0.9341    0.8959    0.9146       759
     neutral     0.5969    0.6536    0.6240       179

    accuracy                         0.8446      1120
   macro avg     0.7637    0.7894    0.7757      1120
weighted avg     0.8519    0.8446    0.8476      1120

03/27/2024 10:30:12 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:30:12 - INFO - trainer -     eval loss: 0.48550723849662714
03/27/2024 10:30:12 - INFO - trainer -     acc = 0.8446428571428571
03/27/2024 10:30:12 - INFO - trainer -     f1 = 0.7756509763037448
03/27/2024 10:30:21 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:30:21 - INFO - trainer -     Num examples = 1120
03/27/2024 10:30:21 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8622    0.6602    0.7478       256
  positivate     0.9574    0.8510    0.9011       819
     neutral     0.1837    0.8000    0.2988        45

    accuracy                         0.8054      1120
   macro avg     0.6678    0.7704    0.6492      1120
weighted avg     0.9046    0.8054    0.8419      1120

03/27/2024 10:30:23 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:30:23 - INFO - trainer -     eval loss: 0.6998312198690005
03/27/2024 10:30:23 - INFO - trainer -     acc = 0.8053571428571429
03/27/2024 10:30:23 - INFO - trainer -     f1 = 0.6492138994801206
03/27/2024 10:30:32 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:30:32 - INFO - trainer -     Num examples = 1120
03/27/2024 10:30:32 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8469    0.7313    0.7849       227
  positivate     0.9602    0.8672    0.9113       806
     neutral     0.3571    0.8046    0.4947        87

    accuracy                         0.8348      1120
   macro avg     0.7214    0.8010    0.7303      1120
weighted avg     0.8904    0.8348    0.8533      1120

03/27/2024 10:30:33 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:30:33 - INFO - trainer -     eval loss: 0.4859842419092144
03/27/2024 10:30:33 - INFO - trainer -     acc = 0.8348214285714286
03/27/2024 10:30:33 - INFO - trainer -     f1 = 0.7303041724653965
Epoch:  10%|█████████▏                                                                                  | 3/30 [01:21<12:32, 27.87s/it]
03/27/2024 10:30:42 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:30:42 - INFO - trainer -     Num examples = 1120
03/27/2024 10:30:42 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7602    0.8054    0.7822       185
  positivate     0.9684    0.8661    0.9144       814
     neutral     0.4592    0.7438    0.5678       121

    accuracy                         0.8429      1120
   macro avg     0.7293    0.8051    0.7548      1120
weighted avg     0.8790    0.8429    0.8551      1120

03/27/2024 10:30:43 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:30:43 - INFO - trainer -     eval loss: 0.560143041397844
03/27/2024 10:30:43 - INFO - trainer -     acc = 0.8428571428571429
03/27/2024 10:30:43 - INFO - trainer -     f1 = 0.7547908206597475
03/27/2024 10:30:53 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:30:53 - INFO - trainer -     Num examples = 1120
03/27/2024 10:30:53 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8163    0.7547    0.7843       212
  positivate     0.9739    0.8563    0.9113       828
     neutral     0.3214    0.7875    0.4565        80

    accuracy                         0.8321      1120
   macro avg     0.7039    0.7995    0.7174      1120
weighted avg     0.8975    0.8321    0.8548      1120

03/27/2024 10:30:54 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:30:54 - INFO - trainer -     eval loss: 0.6386795785810266
03/27/2024 10:30:54 - INFO - trainer -     acc = 0.8321428571428572
03/27/2024 10:30:54 - INFO - trainer -     f1 = 0.7173821728684021
03/27/2024 10:31:03 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:31:03 - INFO - trainer -     Num examples = 1120
03/27/2024 10:31:03 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7806    0.8182    0.7990       187
  positivate     0.9643    0.8797    0.9201       798
     neutral     0.4949    0.7185    0.5861       135

    accuracy                         0.8500      1120
   macro avg     0.7466    0.8055    0.7684      1120
weighted avg     0.8770    0.8500    0.8596      1120

03/27/2024 10:31:04 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:31:04 - INFO - trainer -     eval loss: 0.5478842105982559
03/27/2024 10:31:04 - INFO - trainer -     acc = 0.85
03/27/2024 10:31:04 - INFO - trainer -     f1 = 0.7683702524166124
Epoch:  13%|████████████▎                                                                               | 4/30 [01:51<12:19, 28.43s/it]
03/27/2024 10:31:13 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:31:13 - INFO - trainer -     Num examples = 1120
03/27/2024 10:31:13 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7296    0.8171    0.7709       175
  positivate     0.9190    0.9344    0.9266       716
     neutral     0.7245    0.6201    0.6682       229

    accuracy                         0.8518      1120
   macro avg     0.7910    0.7905    0.7886      1120
weighted avg     0.8496    0.8518    0.8494      1120

03/27/2024 10:31:15 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:31:15 - INFO - trainer -     eval loss: 0.6637093844158309
03/27/2024 10:31:15 - INFO - trainer -     acc = 0.8517857142857143
03/27/2024 10:31:15 - INFO - trainer -     f1 = 0.7885725265907335
03/27/2024 10:31:24 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:31:24 - INFO - trainer -     Num examples = 1120
03/27/2024 10:31:24 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7755    0.8444    0.8085       180
  positivate     0.9629    0.8818    0.9206       795
     neutral     0.5867    0.7931    0.6745       145

    accuracy                         0.8643      1120
   macro avg     0.7751    0.8398    0.8012      1120
weighted avg     0.8841    0.8643    0.8707      1120

03/27/2024 10:31:25 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:31:25 - INFO - trainer -     eval loss: 0.6083236002828926
03/27/2024 10:31:25 - INFO - trainer -     acc = 0.8642857142857143
03/27/2024 10:31:25 - INFO - trainer -     f1 = 0.8011829949413855
Epoch:  17%|███████████████▎                                                                            | 5/30 [02:19<11:46, 28.26s/it]
03/27/2024 10:31:35 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:31:35 - INFO - trainer -     Num examples = 1120
03/27/2024 10:31:35 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7704    0.8162    0.7927       185
  positivate     0.9258    0.9071    0.9164       743
     neutral     0.6071    0.6198    0.6134       192

    accuracy                         0.8429      1120
   macro avg     0.7678    0.7810    0.7741      1120
weighted avg     0.8455    0.8429    0.8440      1120

03/27/2024 10:31:36 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:31:36 - INFO - trainer -     eval loss: 0.6311681293483291
03/27/2024 10:31:36 - INFO - trainer -     acc = 0.8428571428571429
03/27/2024 10:31:36 - INFO - trainer -     f1 = 0.7741454643784333
03/27/2024 10:31:44 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:31:44 - INFO - trainer -     Num examples = 1120
03/27/2024 10:31:44 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8010    0.7772    0.7889       202
  positivate     0.9753    0.8585    0.9132       827
     neutral     0.3622    0.7802    0.4948        91

    accuracy                         0.8375      1120
   macro avg     0.7128    0.8053    0.7323      1120
weighted avg     0.8940    0.8375    0.8568      1120

03/27/2024 10:31:45 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:31:45 - INFO - trainer -     eval loss: 0.8331483248621225
03/27/2024 10:31:45 - INFO - trainer -     acc = 0.8375
03/27/2024 10:31:45 - INFO - trainer -     f1 = 0.7323005075082062
03/27/2024 10:31:53 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:31:53 - INFO - trainer -     Num examples = 1120
03/27/2024 10:31:53 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7092    0.8274    0.7637       168
  positivate     0.9821    0.8522    0.9126       839
     neutral     0.4490    0.7788    0.5696       113

    accuracy                         0.8411      1120
   macro avg     0.7134    0.8194    0.7486      1120
weighted avg     0.8874    0.8411    0.8556      1120

03/27/2024 10:31:54 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:31:54 - INFO - trainer -     eval loss: 0.801774170914931
03/27/2024 10:31:54 - INFO - trainer -     acc = 0.8410714285714286
03/27/2024 10:31:54 - INFO - trainer -     f1 = 0.7486291149992118
Epoch:  20%|██████████████████▍                                                                         | 6/30 [02:45<10:59, 27.48s/it]
03/27/2024 10:32:02 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:32:02 - INFO - trainer -     Num examples = 1120
03/27/2024 10:32:02 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7347    0.8090    0.7701       178
  positivate     0.9766    0.8597    0.9145       827
     neutral     0.4643    0.7913    0.5852       115

    accuracy                         0.8446      1120
   macro avg     0.7252    0.8200    0.7566      1120
weighted avg     0.8856    0.8446    0.8577      1120

03/27/2024 10:32:04 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:32:04 - INFO - trainer -     eval loss: 0.8023645522671619
03/27/2024 10:32:04 - INFO - trainer -     acc = 0.8446428571428571
03/27/2024 10:32:04 - INFO - trainer -     f1 = 0.7565773108424896
03/27/2024 10:32:11 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:32:11 - INFO - trainer -     Num examples = 1120
03/27/2024 10:32:11 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7500    0.7737    0.7617       190
  positivate     0.9821    0.8256    0.8971       866
     neutral     0.2653    0.8125    0.4000        64

    accuracy                         0.8161      1120
   macro avg     0.6658    0.8039    0.6863      1120
weighted avg     0.9018    0.8161    0.8457      1120

03/27/2024 10:32:13 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:32:13 - INFO - trainer -     eval loss: 0.9546036511060915
03/27/2024 10:32:13 - INFO - trainer -     acc = 0.8160714285714286
03/27/2024 10:32:13 - INFO - trainer -     f1 = 0.6862574030854045
03/27/2024 10:32:21 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:32:21 - INFO - trainer -     Num examples = 1120
03/27/2024 10:32:21 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7347    0.7701    0.7520       187
  positivate     0.9808    0.8440    0.9072       846
     neutral     0.3367    0.7586    0.4664        87

    accuracy                         0.8250      1120
   macro avg     0.6841    0.7909    0.7085      1120
weighted avg     0.8897    0.8250    0.8471      1120

03/27/2024 10:32:22 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:32:22 - INFO - trainer -     eval loss: 0.8295722474277551
03/27/2024 10:32:22 - INFO - trainer -     acc = 0.825
03/27/2024 10:32:22 - INFO - trainer -     f1 = 0.7085440045744219
Epoch:  23%|█████████████████████▍                                                                      | 7/30 [03:11<10:19, 26.95s/it]
03/27/2024 10:32:30 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:32:30 - INFO - trainer -     Num examples = 1120
03/27/2024 10:32:30 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7041    0.7931    0.7459       174
  positivate     0.9657    0.8470    0.9024       830
     neutral     0.4286    0.7241    0.5385       116

    accuracy                         0.8259      1120
   macro avg     0.6994    0.7881    0.7289      1120
weighted avg     0.8694    0.8259    0.8404      1120

03/27/2024 10:32:31 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:32:31 - INFO - trainer -     eval loss: 0.9660925572189236
03/27/2024 10:32:31 - INFO - trainer -     acc = 0.8258928571428571
03/27/2024 10:32:31 - INFO - trainer -     f1 = 0.7289488362659095
03/27/2024 10:32:39 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:32:39 - INFO - trainer -     Num examples = 1120
03/27/2024 10:32:39 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7806    0.7251    0.7518       211
  positivate     0.9725    0.8540    0.9094       829
     neutral     0.3163    0.7750    0.4493        80

    accuracy                         0.8241      1120
   macro avg     0.6898    0.7847    0.7035      1120
weighted avg     0.8895    0.8241    0.8469      1120

03/27/2024 10:32:41 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:32:41 - INFO - trainer -     eval loss: 1.062728041776323
03/27/2024 10:32:41 - INFO - trainer -     acc = 0.8241071428571428
03/27/2024 10:32:41 - INFO - trainer -     f1 = 0.7035197824340825
03/27/2024 10:32:49 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:32:49 - INFO - trainer -     Num examples = 1120
03/27/2024 10:32:49 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7449    0.8111    0.7766       180
  positivate     0.9780    0.8446    0.9064       843
     neutral     0.3929    0.7938    0.5256        97

    accuracy                         0.8348      1120
   macro avg     0.7053    0.8165    0.7362      1120
weighted avg     0.8899    0.8348    0.8526      1120

03/27/2024 10:32:50 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:32:50 - INFO - trainer -     eval loss: 0.8975859001278877
03/27/2024 10:32:50 - INFO - trainer -     acc = 0.8348214285714286
03/27/2024 10:32:50 - INFO - trainer -     f1 = 0.7362073468011504
Epoch:  27%|████████████████████████▌                                                                   | 8/30 [03:36<09:45, 26.61s/it]
03/27/2024 10:32:58 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:32:58 - INFO - trainer -     Num examples = 1120
03/27/2024 10:32:58 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8061    0.7783    0.7920       203
  positivate     0.9286    0.9098    0.9191       743
     neutral     0.5969    0.6724    0.6324       174

    accuracy                         0.8491      1120
   macro avg     0.7772    0.7869    0.7812      1120
weighted avg     0.8549    0.8491    0.8515      1120

03/27/2024 10:32:59 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:32:59 - INFO - trainer -     eval loss: 0.6712167486814516
03/27/2024 10:32:59 - INFO - trainer -     acc = 0.8491071428571428
03/27/2024 10:32:59 - INFO - trainer -     f1 = 0.7811716778549224
03/27/2024 10:33:07 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:33:07 - INFO - trainer -     Num examples = 1120
03/27/2024 10:33:07 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7500    0.7819    0.7656       188
  positivate     0.9533    0.8774    0.9138       791
     neutral     0.5153    0.7163    0.5994       141

    accuracy                         0.8411      1120
   macro avg     0.7395    0.7919    0.7596      1120
weighted avg     0.8640    0.8411    0.8493      1120

03/27/2024 10:33:08 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:33:08 - INFO - trainer -     eval loss: 0.8381434853587831
03/27/2024 10:33:08 - INFO - trainer -     acc = 0.8410714285714286
03/27/2024 10:33:08 - INFO - trainer -     f1 = 0.759596860065937
Epoch:  30%|███████████████████████████▌                                                                | 9/30 [04:01<09:04, 25.91s/it]
03/27/2024 10:33:16 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:33:16 - INFO - trainer -     Num examples = 1120
03/27/2024 10:33:16 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7806    0.8010    0.7907       191
  positivate     0.9739    0.8522    0.9090       832
     neutral     0.3980    0.8041    0.5324        97

    accuracy                         0.8393      1120
   macro avg     0.7175    0.8191    0.7440      1120
weighted avg     0.8911    0.8393    0.8562      1120

03/27/2024 10:33:18 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:33:18 - INFO - trainer -     eval loss: 0.9647683958789067
03/27/2024 10:33:18 - INFO - trainer -     acc = 0.8392857142857143
03/27/2024 10:33:18 - INFO - trainer -     f1 = 0.7440317471946966
03/27/2024 10:33:26 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:33:26 - INFO - trainer -     Num examples = 1120
03/27/2024 10:33:26 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7551    0.7957    0.7749       186
  positivate     0.9451    0.8832    0.9131       779
     neutral     0.5459    0.6903    0.6097       155

    accuracy                         0.8420      1120
   macro avg     0.7487    0.7897    0.7659      1120
weighted avg     0.8583    0.8420    0.8481      1120

03/27/2024 10:33:27 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:33:27 - INFO - trainer -     eval loss: 0.9963217090283122
03/27/2024 10:33:27 - INFO - trainer -     acc = 0.8419642857142857
03/27/2024 10:33:27 - INFO - trainer -     f1 = 0.7658760162549924
03/27/2024 10:33:35 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:33:35 - INFO - trainer -     Num examples = 1120
03/27/2024 10:33:35 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7296    0.7944    0.7606       180
  positivate     0.9354    0.8996    0.9172       757
     neutral     0.6327    0.6776    0.6544       183

    accuracy                         0.8464      1120
   macro avg     0.7659    0.7905    0.7774      1120
weighted avg     0.8529    0.8464    0.8491      1120

03/27/2024 10:33:36 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:33:36 - INFO - trainer -     eval loss: 0.7754534597641656
03/27/2024 10:33:36 - INFO - trainer -     acc = 0.8464285714285714
03/27/2024 10:33:36 - INFO - trainer -     f1 = 0.7773878590164448
Epoch:  33%|██████████████████████████████▎                                                            | 10/30 [04:27<08:38, 25.93s/it]
03/27/2024 10:33:44 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:33:44 - INFO - trainer -     Num examples = 1120
03/27/2024 10:33:44 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7959    0.7429    0.7685       210
  positivate     0.9533    0.8785    0.9144       790
     neutral     0.4439    0.7250    0.5506       120

    accuracy                         0.8366      1120
   macro avg     0.7310    0.7821    0.7445      1120
weighted avg     0.8692    0.8366    0.8480      1120

03/27/2024 10:33:45 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:33:45 - INFO - trainer -     eval loss: 0.897326386214367
03/27/2024 10:33:45 - INFO - trainer -     acc = 0.8366071428571429
03/27/2024 10:33:45 - INFO - trainer -     f1 = 0.744488939704623
03/27/2024 10:33:53 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:33:53 - INFO - trainer -     Num examples = 1120
03/27/2024 10:33:53 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.6990    0.8457    0.7654       162
  positivate     0.9327    0.8841    0.9078       768
     neutral     0.6224    0.6421    0.6321       190

    accuracy                         0.8375      1120
   macro avg     0.7514    0.7906    0.7684      1120
weighted avg     0.8463    0.8375    0.8404      1120

03/27/2024 10:33:55 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:33:55 - INFO - trainer -     eval loss: 0.9034672155111496
03/27/2024 10:33:55 - INFO - trainer -     acc = 0.8375
03/27/2024 10:33:55 - INFO - trainer -     f1 = 0.7684138305061379
03/27/2024 10:34:03 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:34:03 - INFO - trainer -     Num examples = 1120
03/27/2024 10:34:03 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7449    0.7892    0.7664       185
  positivate     0.9451    0.8798    0.9113       782
     neutral     0.5306    0.6797    0.5960       153

    accuracy                         0.8375      1120
   macro avg     0.7402    0.7829    0.7579      1120
weighted avg     0.8554    0.8375    0.8443      1120

03/27/2024 10:34:04 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:34:04 - INFO - trainer -     eval loss: 0.8763232049266142
03/27/2024 10:34:04 - INFO - trainer -     acc = 0.8375
03/27/2024 10:34:04 - INFO - trainer -     f1 = 0.7578836721009031
Epoch:  37%|█████████████████████████████████▎                                                         | 11/30 [04:53<08:12, 25.93s/it]
03/27/2024 10:34:12 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:34:12 - INFO - trainer -     Num examples = 1120
03/27/2024 10:34:12 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8061    0.7745    0.7900       204
  positivate     0.9354    0.8787    0.9062       775
     neutral     0.4796    0.6667    0.5579       141

    accuracy                         0.8330      1120
   macro avg     0.7404    0.7733    0.7514      1120
weighted avg     0.8545    0.8330    0.8412      1120

03/27/2024 10:34:13 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:34:13 - INFO - trainer -     eval loss: 1.1492393997747319
03/27/2024 10:34:13 - INFO - trainer -     acc = 0.8330357142857143
03/27/2024 10:34:13 - INFO - trainer -     f1 = 0.7513503754113929
03/27/2024 10:34:21 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:34:21 - INFO - trainer -     Num examples = 1120
03/27/2024 10:34:21 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7704    0.7704    0.7704       196
  positivate     0.9808    0.8470    0.9090       843
     neutral     0.3316    0.8025    0.4693        81

    accuracy                         0.8304      1120
   macro avg     0.6943    0.8066    0.7162      1120
weighted avg     0.8970    0.8304    0.8529      1120

03/27/2024 10:34:22 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:34:22 - INFO - trainer -     eval loss: 1.186068463771205
03/27/2024 10:34:22 - INFO - trainer -     acc = 0.8303571428571429
03/27/2024 10:34:22 - INFO - trainer -     f1 = 0.7162324725784764
03/27/2024 10:34:30 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:34:30 - INFO - trainer -     Num examples = 1120
03/27/2024 10:34:30 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8316    0.7617    0.7951       214
  positivate     0.9629    0.8719    0.9151       804
     neutral     0.4133    0.7941    0.5436       102

    accuracy                         0.8438      1120
   macro avg     0.7359    0.8092    0.7513      1120
weighted avg     0.8878    0.8438    0.8584      1120

03/27/2024 10:34:32 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:34:32 - INFO - trainer -     eval loss: 1.1252228526897463
03/27/2024 10:34:32 - INFO - trainer -     acc = 0.84375
03/27/2024 10:34:32 - INFO - trainer -     f1 = 0.7512965718088322
Epoch:  40%|████████████████████████████████████▍                                                      | 12/30 [05:19<07:46, 25.93s/it]
03/27/2024 10:34:40 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:34:40 - INFO - trainer -     Num examples = 1120
03/27/2024 10:34:40 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7704    0.8207    0.7947       184
  positivate     0.9547    0.8979    0.9254       774
     neutral     0.5816    0.7037    0.6369       162

    accuracy                         0.8571      1120
   macro avg     0.7689    0.8074    0.7857      1120
weighted avg     0.8704    0.8571    0.8622      1120

03/27/2024 10:34:41 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:34:41 - INFO - trainer -     eval loss: 1.0258790034630303
03/27/2024 10:34:41 - INFO - trainer -     acc = 0.8571428571428571
03/27/2024 10:34:41 - INFO - trainer -     f1 = 0.7856803689366839
03/27/2024 10:34:49 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:34:49 - INFO - trainer -     Num examples = 1120
03/27/2024 10:34:49 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7959    0.7573    0.7761       206
  positivate     0.9560    0.8603    0.9057       809
     neutral     0.4031    0.7524    0.5249       105

    accuracy                         0.8313      1120
   macro avg     0.7183    0.7900    0.7356      1120
weighted avg     0.8748    0.8313    0.8461      1120

03/27/2024 10:34:50 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:34:50 - INFO - trainer -     eval loss: 0.9475554749369621
03/27/2024 10:34:50 - INFO - trainer -     acc = 0.83125
03/27/2024 10:34:50 - INFO - trainer -     f1 = 0.7355655746217199
Epoch:  43%|███████████████████████████████████████▍                                                   | 13/30 [05:43<07:14, 25.54s/it]
03/27/2024 10:34:58 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:34:58 - INFO - trainer -     Num examples = 1120
03/27/2024 10:34:58 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7908    0.7828    0.7868       198
  positivate     0.9574    0.8924    0.9238       781
     neutral     0.5306    0.7376    0.6172       141

    accuracy                         0.8536      1120
   macro avg     0.7596    0.8043    0.7759      1120
weighted avg     0.8742    0.8536    0.8610      1120

03/27/2024 10:35:00 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:35:00 - INFO - trainer -     eval loss: 0.8969802616363657
03/27/2024 10:35:00 - INFO - trainer -     acc = 0.8535714285714285
03/27/2024 10:35:00 - INFO - trainer -     f1 = 0.7759344342480001
03/27/2024 10:35:08 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:35:08 - INFO - trainer -     Num examples = 1120
03/27/2024 10:35:08 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7959    0.7839    0.7899       199
  positivate     0.9643    0.8897    0.9255       789
     neutral     0.5306    0.7879    0.6341       132

    accuracy                         0.8589      1120
   macro avg     0.7636    0.8205    0.7832      1120
weighted avg     0.8833    0.8589    0.8671      1120

03/27/2024 10:35:09 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:35:09 - INFO - trainer -     eval loss: 1.0182238729429498
03/27/2024 10:35:09 - INFO - trainer -     acc = 0.8589285714285714
03/27/2024 10:35:09 - INFO - trainer -     f1 = 0.7831768786384409
03/27/2024 10:35:17 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:35:17 - INFO - trainer -     Num examples = 1120
03/27/2024 10:35:17 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.6837    0.8645    0.7635       155
  positivate     0.9725    0.8479    0.9060       835
     neutral     0.4745    0.7154    0.5706       130

    accuracy                         0.8348      1120
   macro avg     0.7102    0.8093    0.7467      1120
weighted avg     0.8747    0.8348    0.8473      1120

03/27/2024 10:35:18 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:35:18 - INFO - trainer -     eval loss: 0.9475084114753242
03/27/2024 10:35:18 - INFO - trainer -     acc = 0.8348214285714286
03/27/2024 10:35:18 - INFO - trainer -     f1 = 0.7466783355804392
Epoch:  47%|██████████████████████████████████████████▍                                                | 14/30 [06:09<06:50, 25.66s/it]
03/27/2024 10:35:26 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:35:26 - INFO - trainer -     Num examples = 1120
03/27/2024 10:35:26 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7959    0.7723    0.7839       202
  positivate     0.9464    0.9007    0.9230       765
     neutral     0.5765    0.7386    0.6476       153

    accuracy                         0.8554      1120
   macro avg     0.7730    0.8038    0.7848      1120
weighted avg     0.8688    0.8554    0.8603      1120

03/27/2024 10:35:27 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:35:27 - INFO - trainer -     eval loss: 0.9534902978621955
03/27/2024 10:35:27 - INFO - trainer -     acc = 0.8553571428571428
03/27/2024 10:35:27 - INFO - trainer -     f1 = 0.7848193153339266
03/27/2024 10:35:35 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:35:35 - INFO - trainer -     Num examples = 1120
03/27/2024 10:35:35 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7755    0.7451    0.7600       204
  positivate     0.9684    0.8640    0.9132       816
     neutral     0.4133    0.8100    0.5473       100

    accuracy                         0.8375      1120
   macro avg     0.7191    0.8064    0.7402      1120
weighted avg     0.8837    0.8375    0.8526      1120

03/27/2024 10:35:37 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:35:37 - INFO - trainer -     eval loss: 1.1375390480987595
03/27/2024 10:35:37 - INFO - trainer -     acc = 0.8375
03/27/2024 10:35:37 - INFO - trainer -     f1 = 0.7401699108434859
03/27/2024 10:35:45 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:35:45 - INFO - trainer -     Num examples = 1120
03/27/2024 10:35:45 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7143    0.7735    0.7427       181
  positivate     0.9835    0.8326    0.9018       860
     neutral     0.3214    0.7975    0.4582        79

    accuracy                         0.8205      1120
   macro avg     0.6731    0.8012    0.7009      1120
weighted avg     0.8933    0.8205    0.8448      1120

03/27/2024 10:35:46 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:35:46 - INFO - trainer -     eval loss: 1.3499684681068174
03/27/2024 10:35:46 - INFO - trainer -     acc = 0.8205357142857143
03/27/2024 10:35:46 - INFO - trainer -     f1 = 0.7008835375516518
Epoch:  50%|█████████████████████████████████████████████▌                                             | 15/30 [06:35<06:25, 25.71s/it]
03/27/2024 10:35:54 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:35:54 - INFO - trainer -     Num examples = 1120
03/27/2024 10:35:54 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7857    0.8063    0.7959       191
  positivate     0.9739    0.8625    0.9148       822
     neutral     0.4286    0.7850    0.5545       107

    accuracy                         0.8455      1120
   macro avg     0.7294    0.8180    0.7551      1120
weighted avg     0.8897    0.8455    0.8601      1120

03/27/2024 10:35:55 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:35:55 - INFO - trainer -     eval loss: 1.1911229159558259
03/27/2024 10:35:55 - INFO - trainer -     acc = 0.8455357142857143
03/27/2024 10:35:55 - INFO - trainer -     f1 = 0.7550532627656364
03/27/2024 10:36:03 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:36:03 - INFO - trainer -     Num examples = 1120
03/27/2024 10:36:03 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7653    0.7353    0.7500       204
  positivate     0.9698    0.8652    0.9145       816
     neutral     0.4082    0.8000    0.5405       100

    accuracy                         0.8357      1120
   macro avg     0.7144    0.8002    0.7350      1120
weighted avg     0.8824    0.8357    0.8512      1120

03/27/2024 10:36:04 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:36:04 - INFO - trainer -     eval loss: 1.2317877228313592
03/27/2024 10:36:04 - INFO - trainer -     acc = 0.8357142857142857
03/27/2024 10:36:04 - INFO - trainer -     f1 = 0.7350161041870887
03/27/2024 10:36:12 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:36:12 - INFO - trainer -     Num examples = 1120
03/27/2024 10:36:12 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7296    0.7688    0.7487       186
  positivate     0.9725    0.8592    0.9124       824
     neutral     0.4337    0.7727    0.5556       110

    accuracy                         0.8357      1120
   macro avg     0.7119    0.8003    0.7389      1120
weighted avg     0.8793    0.8357    0.8501      1120

03/27/2024 10:36:14 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:36:14 - INFO - trainer -     eval loss: 1.2275779234295312
03/27/2024 10:36:14 - INFO - trainer -     acc = 0.8357142857142857
03/27/2024 10:36:14 - INFO - trainer -     f1 = 0.7388725963508712
Epoch:  53%|████████████████████████████████████████████████▌                                          | 16/30 [07:01<06:00, 25.77s/it]
03/27/2024 10:36:22 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:36:22 - INFO - trainer -     Num examples = 1120
03/27/2024 10:36:22 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7296    0.7944    0.7606       180
  positivate     0.9739    0.8657    0.9166       819
     neutral     0.4643    0.7521    0.5741       121

    accuracy                         0.8420      1120
   macro avg     0.7226    0.8041    0.7505      1120
weighted avg     0.8796    0.8420    0.8545      1120

03/27/2024 10:36:23 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:36:23 - INFO - trainer -     eval loss: 1.1554524745110288
03/27/2024 10:36:23 - INFO - trainer -     acc = 0.8419642857142857
03/27/2024 10:36:23 - INFO - trainer -     f1 = 0.7504611963172151
03/27/2024 10:36:32 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:36:32 - INFO - trainer -     Num examples = 1120
03/27/2024 10:36:32 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7806    0.7537    0.7669       203
  positivate     0.9643    0.8667    0.9129       810
     neutral     0.3980    0.7290    0.5149       107

    accuracy                         0.8330      1120
   macro avg     0.7143    0.7831    0.7315      1120
weighted avg     0.8769    0.8330    0.8484      1120

03/27/2024 10:36:33 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:36:33 - INFO - trainer -     eval loss: 1.2223998422106628
03/27/2024 10:36:33 - INFO - trainer -     acc = 0.8330357142857143
03/27/2024 10:36:33 - INFO - trainer -     f1 = 0.7315475468467484
Epoch:  57%|███████████████████████████████████████████████████▌                                       | 17/30 [07:28<05:38, 26.04s/it]
03/27/2024 10:36:42 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:36:42 - INFO - trainer -     Num examples = 1120
03/27/2024 10:36:42 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8214    0.7124    0.7630       226
  positivate     0.9698    0.8558    0.9092       825
     neutral     0.2857    0.8116    0.4226        69

    accuracy                         0.8241      1120
   macro avg     0.6923    0.7932    0.6983      1120
weighted avg     0.8977    0.8241    0.8497      1120

03/27/2024 10:36:44 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:36:44 - INFO - trainer -     eval loss: 1.3675438463504959
03/27/2024 10:36:44 - INFO - trainer -     acc = 0.8241071428571428
03/27/2024 10:36:44 - INFO - trainer -     f1 = 0.6982942231118175
03/27/2024 10:36:53 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:36:53 - INFO - trainer -     Num examples = 1120
03/27/2024 10:36:53 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7500    0.8305    0.7882       177
  positivate     0.9766    0.8546    0.9115       832
     neutral     0.4541    0.8018    0.5798       111

    accuracy                         0.8455      1120
   macro avg     0.7269    0.8290    0.7598      1120
weighted avg     0.8890    0.8455    0.8592      1120

03/27/2024 10:36:54 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:36:54 - INFO - trainer -     eval loss: 1.0234217809330273
03/27/2024 10:36:54 - INFO - trainer -     acc = 0.8455357142857143
03/27/2024 10:36:54 - INFO - trainer -     f1 = 0.7598489250500847
03/27/2024 10:37:04 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:37:04 - INFO - trainer -     Num examples = 1120
03/27/2024 10:37:04 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.6888    0.8491    0.7606       159
  positivate     0.9725    0.8520    0.9083       831
     neutral     0.5102    0.7692    0.6135       130

    accuracy                         0.8420      1120
   macro avg     0.7238    0.8234    0.7608      1120
weighted avg     0.8786    0.8420    0.8531      1120

03/27/2024 10:37:05 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:37:05 - INFO - trainer -     eval loss: 1.1482249985848154
03/27/2024 10:37:05 - INFO - trainer -     acc = 0.8419642857142857
03/27/2024 10:37:05 - INFO - trainer -     f1 = 0.7607782825851114
Epoch:  60%|██████████████████████████████████████████████████████▌                                    | 18/30 [07:56<05:21, 26.75s/it]
03/27/2024 10:37:13 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:37:13 - INFO - trainer -     Num examples = 1120
03/27/2024 10:37:13 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8265    0.7642    0.7941       212
  positivate     0.9272    0.9060    0.9165       745
     neutral     0.5969    0.7178    0.6518       163

    accuracy                         0.8518      1120
   macro avg     0.7836    0.7960    0.7875      1120
weighted avg     0.8601    0.8518    0.8548      1120

03/27/2024 10:37:14 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:37:14 - INFO - trainer -     eval loss: 1.0710098224284592
03/27/2024 10:37:14 - INFO - trainer -     acc = 0.8517857142857143
03/27/2024 10:37:14 - INFO - trainer -     f1 = 0.7874750590090747
03/27/2024 10:37:22 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:37:22 - INFO - trainer -     Num examples = 1120
03/27/2024 10:37:22 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7653    0.8065    0.7853       186
  positivate     0.9753    0.8627    0.9155       823
     neutral     0.4439    0.7838    0.5668       111

    accuracy                         0.8455      1120
   macro avg     0.7282    0.8176    0.7559      1120
weighted avg     0.8877    0.8455    0.8594      1120

03/27/2024 10:37:23 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:37:23 - INFO - trainer -     eval loss: 1.2211400405670116
03/27/2024 10:37:23 - INFO - trainer -     acc = 0.8455357142857143
03/27/2024 10:37:23 - INFO - trainer -     f1 = 0.7558846402608911
03/27/2024 10:37:31 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:37:31 - INFO - trainer -     Num examples = 1120
03/27/2024 10:37:31 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7857    0.7739    0.7797       199
  positivate     0.9712    0.8622    0.9134       820
     neutral     0.4235    0.8218    0.5589       101

    accuracy                         0.8429      1120
   macro avg     0.7268    0.8193    0.7507      1120
weighted avg     0.8888    0.8429    0.8577      1120

03/27/2024 10:37:32 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:37:32 - INFO - trainer -     eval loss: 1.3223351074781802
03/27/2024 10:37:32 - INFO - trainer -     acc = 0.8428571428571429
03/27/2024 10:37:32 - INFO - trainer -     f1 = 0.7507020289573524
Epoch:  63%|█████████████████████████████████████████████████████████▋                                 | 19/30 [08:22<04:50, 26.45s/it]
03/27/2024 10:37:40 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:37:40 - INFO - trainer -     Num examples = 1120
03/27/2024 10:37:40 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8673    0.7143    0.7834       238
  positivate     0.9272    0.9000    0.9134       750
     neutral     0.5153    0.7652    0.6159       132

    accuracy                         0.8446      1120
   macro avg     0.7700    0.7931    0.7709      1120
weighted avg     0.8659    0.8446    0.8507      1120

03/27/2024 10:37:42 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:37:42 - INFO - trainer -     eval loss: 1.1697748708031472
03/27/2024 10:37:42 - INFO - trainer -     acc = 0.8446428571428571
03/27/2024 10:37:42 - INFO - trainer -     f1 = 0.7708867595058345
03/27/2024 10:37:50 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:37:50 - INFO - trainer -     Num examples = 1120
03/27/2024 10:37:50 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7755    0.8128    0.7937       187
  positivate     0.9423    0.8932    0.9171       768
     neutral     0.6173    0.7333    0.6704       165

    accuracy                         0.8562      1120
   macro avg     0.7784    0.8131    0.7937      1120
weighted avg     0.8666    0.8562    0.8602      1120

03/27/2024 10:37:51 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:37:51 - INFO - trainer -     eval loss: 1.1107694081342612
03/27/2024 10:37:51 - INFO - trainer -     acc = 0.85625
03/27/2024 10:37:51 - INFO - trainer -     f1 = 0.7937353639102351
03/27/2024 10:37:59 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:37:59 - INFO - trainer -     Num examples = 1120
03/27/2024 10:37:59 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7398    0.8239    0.7796       176
  positivate     0.9574    0.8723    0.9129       799
     neutral     0.5306    0.7172    0.6100       145

    accuracy                         0.8446      1120
   macro avg     0.7426    0.8045    0.7675      1120
weighted avg     0.8680    0.8446    0.8527      1120

03/27/2024 10:38:00 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:38:00 - INFO - trainer -     eval loss: 1.2527596831529602
03/27/2024 10:38:00 - INFO - trainer -     acc = 0.8446428571428571
03/27/2024 10:38:00 - INFO - trainer -     f1 = 0.7674805600846542
Epoch:  67%|████████████████████████████████████████████████████████████▋                              | 20/30 [08:48<04:23, 26.32s/it]
03/27/2024 10:38:08 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:38:08 - INFO - trainer -     Num examples = 1120
03/27/2024 10:38:08 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7347    0.8276    0.7784       174
  positivate     0.9505    0.8929    0.9208       775
     neutral     0.6071    0.6959    0.6485       171

    accuracy                         0.8527      1120
   macro avg     0.7641    0.8055    0.7826      1120
weighted avg     0.8646    0.8527    0.8571      1120

03/27/2024 10:38:09 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:38:09 - INFO - trainer -     eval loss: 1.2114566079432345
03/27/2024 10:38:09 - INFO - trainer -     acc = 0.8526785714285714
03/27/2024 10:38:09 - INFO - trainer -     f1 = 0.7825682524698662
03/27/2024 10:38:17 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:38:17 - INFO - trainer -     Num examples = 1120
03/27/2024 10:38:17 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8367    0.7489    0.7904       219
  positivate     0.9437    0.8876    0.9148       774
     neutral     0.4847    0.7480    0.5882       127

    accuracy                         0.8446      1120
   macro avg     0.7550    0.7948    0.7645      1120
weighted avg     0.8707    0.8446    0.8534      1120

03/27/2024 10:38:19 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:38:19 - INFO - trainer -     eval loss: 1.2132792714197422
03/27/2024 10:38:19 - INFO - trainer -     acc = 0.8446428571428571
03/27/2024 10:38:19 - INFO - trainer -     f1 = 0.7644590109478409
Epoch:  70%|███████████████████████████████████████████████████████████████▋                           | 21/30 [09:12<03:51, 25.75s/it]
03/27/2024 10:38:27 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:38:27 - INFO - trainer -     Num examples = 1120
03/27/2024 10:38:27 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7092    0.8274    0.7637       168
  positivate     0.9780    0.8269    0.8962       861
     neutral     0.3724    0.8022    0.5087        91

    accuracy                         0.8250      1120
   macro avg     0.6866    0.8188    0.7229      1120
weighted avg     0.8885    0.8250    0.8448      1120

03/27/2024 10:38:28 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:38:28 - INFO - trainer -     eval loss: 1.3457126881278652
03/27/2024 10:38:28 - INFO - trainer -     acc = 0.825
03/27/2024 10:38:28 - INFO - trainer -     f1 = 0.7228693909149481
03/27/2024 10:38:36 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:38:36 - INFO - trainer -     Num examples = 1120
03/27/2024 10:38:36 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.6735    0.8354    0.7458       158
  positivate     0.9808    0.8312    0.8998       859
     neutral     0.4133    0.7864    0.5418       103

    accuracy                         0.8277      1120
   macro avg     0.6892    0.8177    0.7291      1120
weighted avg     0.8852    0.8277    0.8452      1120

03/27/2024 10:38:37 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:38:37 - INFO - trainer -     eval loss: 1.4191644414097286
03/27/2024 10:38:37 - INFO - trainer -     acc = 0.8276785714285714
03/27/2024 10:38:37 - INFO - trainer -     f1 = 0.7291265653381575
03/27/2024 10:38:45 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:38:45 - INFO - trainer -     Num examples = 1120
03/27/2024 10:38:45 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8367    0.7455    0.7885       220
  positivate     0.9533    0.8875    0.9192       782
     neutral     0.4541    0.7542    0.5669       118

    accuracy                         0.8455      1120
   macro avg     0.7480    0.7957    0.7582      1120
weighted avg     0.8778    0.8455    0.8564      1120

03/27/2024 10:38:47 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:38:47 - INFO - trainer -     eval loss: 1.2448402093180837
03/27/2024 10:38:47 - INFO - trainer -     acc = 0.8455357142857143
03/27/2024 10:38:47 - INFO - trainer -     f1 = 0.7581819391221677
Epoch:  73%|██████████████████████████████████████████████████████████████████▋                        | 22/30 [09:38<03:26, 25.75s/it]
03/27/2024 10:38:54 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:38:54 - INFO - trainer -     Num examples = 1120
03/27/2024 10:38:54 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7296    0.8125    0.7688       176
  positivate     0.9753    0.8402    0.9027       845
     neutral     0.3776    0.7475    0.5017        99

    accuracy                         0.8277      1120
   macro avg     0.6941    0.8001    0.7244      1120
weighted avg     0.8838    0.8277    0.8462      1120

03/27/2024 10:38:56 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:38:56 - INFO - trainer -     eval loss: 1.4855282989983347
03/27/2024 10:38:56 - INFO - trainer -     acc = 0.8276785714285714
03/27/2024 10:38:56 - INFO - trainer -     f1 = 0.7244152498538899
03/27/2024 10:39:03 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:39:03 - INFO - trainer -     Num examples = 1120
03/27/2024 10:39:03 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7806    0.8138    0.7969       188
  positivate     0.9492    0.8882    0.9177       778
     neutral     0.5765    0.7338    0.6457       154

    accuracy                         0.8545      1120
   macro avg     0.7688    0.8119    0.7868      1120
weighted avg     0.8696    0.8545    0.8600      1120

03/27/2024 10:39:05 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:39:05 - INFO - trainer -     eval loss: 1.1980518833048077
03/27/2024 10:39:05 - INFO - trainer -     acc = 0.8544642857142857
03/27/2024 10:39:05 - INFO - trainer -     f1 = 0.7867506561057359
03/27/2024 10:39:13 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:39:13 - INFO - trainer -     Num examples = 1120
03/27/2024 10:39:13 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7908    0.7524    0.7711       206
  positivate     0.9712    0.8622    0.9134       820
     neutral     0.3776    0.7872    0.5103        94

    accuracy                         0.8357      1120
   macro avg     0.7132    0.8006    0.7316      1120
weighted avg     0.8882    0.8357    0.8534      1120

03/27/2024 10:39:14 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:39:14 - INFO - trainer -     eval loss: 1.3295783530143257
03/27/2024 10:39:14 - INFO - trainer -     acc = 0.8357142857142857
03/27/2024 10:39:14 - INFO - trainer -     f1 = 0.7316419328998774
Epoch:  77%|█████████████████████████████████████████████████████████████████████▊                     | 23/30 [10:04<03:00, 25.85s/it]
03/27/2024 10:39:22 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:39:22 - INFO - trainer -     Num examples = 1120
03/27/2024 10:39:22 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8418    0.6962    0.7621       237
  positivate     0.9148    0.8964    0.9055       743
     neutral     0.4847    0.6786    0.5655       140

    accuracy                         0.8268      1120
   macro avg     0.7471    0.7570    0.7444      1120
weighted avg     0.8456    0.8268    0.8327      1120

03/27/2024 10:39:24 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:39:24 - INFO - trainer -     eval loss: 1.1974405467813736
03/27/2024 10:39:24 - INFO - trainer -     acc = 0.8267857142857142
03/27/2024 10:39:24 - INFO - trainer -     f1 = 0.7443691199947647
03/27/2024 10:39:32 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:39:32 - INFO - trainer -     Num examples = 1120
03/27/2024 10:39:32 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7704    0.8075    0.7885       187
  positivate     0.9602    0.8748    0.9155       799
     neutral     0.4694    0.6866    0.5576       134

    accuracy                         0.8411      1120
   macro avg     0.7333    0.7896    0.7539      1120
weighted avg     0.8698    0.8411    0.8515      1120

03/27/2024 10:39:33 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:39:33 - INFO - trainer -     eval loss: 1.3058389631475231
03/27/2024 10:39:33 - INFO - trainer -     acc = 0.8410714285714286
03/27/2024 10:39:33 - INFO - trainer -     f1 = 0.7538693785355699
03/27/2024 10:39:41 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:39:41 - INFO - trainer -     Num examples = 1120
03/27/2024 10:39:41 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7398    0.8333    0.7838       174
  positivate     0.9409    0.8793    0.9091       779
     neutral     0.5459    0.6407    0.5895       167

    accuracy                         0.8366      1120
   macro avg     0.7422    0.7845    0.7608      1120
weighted avg     0.8508    0.8366    0.8420      1120

03/27/2024 10:39:42 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:39:42 - INFO - trainer -     eval loss: 1.292215914085474
03/27/2024 10:39:42 - INFO - trainer -     acc = 0.8366071428571429
03/27/2024 10:39:42 - INFO - trainer -     f1 = 0.760802124438488
Epoch:  80%|████████████████████████████████████████████████████████████████████████▊                  | 24/30 [10:30<02:35, 25.88s/it]
03/27/2024 10:39:50 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:39:50 - INFO - trainer -     Num examples = 1120
03/27/2024 10:39:50 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7398    0.8286    0.7817       175
  positivate     0.9547    0.8709    0.9109       798
     neutral     0.5255    0.7007    0.6006       147

    accuracy                         0.8420      1120
   macro avg     0.7400    0.8001    0.7644      1120
weighted avg     0.8648    0.8420    0.8500      1120

03/27/2024 10:39:51 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:39:51 - INFO - trainer -     eval loss: 1.360979788851234
03/27/2024 10:39:51 - INFO - trainer -     acc = 0.8419642857142857
03/27/2024 10:39:51 - INFO - trainer -     f1 = 0.7643774540405445
03/27/2024 10:39:59 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:39:59 - INFO - trainer -     Num examples = 1120
03/27/2024 10:39:59 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7296    0.8218    0.7730       174
  positivate     0.9670    0.8659    0.9137       813
     neutral     0.4694    0.6917    0.5593       133

    accuracy                         0.8384      1120
   macro avg     0.7220    0.7932    0.7486      1120
weighted avg     0.8710    0.8384    0.8497      1120

03/27/2024 10:40:01 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:40:01 - INFO - trainer -     eval loss: 1.4708427236493402
03/27/2024 10:40:01 - INFO - trainer -     acc = 0.8383928571428572
03/27/2024 10:40:01 - INFO - trainer -     f1 = 0.7486452990726259
03/27/2024 10:40:08 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:40:08 - INFO - trainer -     Num examples = 1120
03/27/2024 10:40:08 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7959    0.7919    0.7939       197
  positivate     0.9547    0.8753    0.9133       794
     neutral     0.4643    0.7054    0.5600       129

    accuracy                         0.8411      1120
   macro avg     0.7383    0.7909    0.7557      1120
weighted avg     0.8703    0.8411    0.8516      1120

03/27/2024 10:40:10 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:40:10 - INFO - trainer -     eval loss: 1.344066756983271
03/27/2024 10:40:10 - INFO - trainer -     acc = 0.8410714285714286
03/27/2024 10:40:10 - INFO - trainer -     f1 = 0.7557217134278252
Epoch:  83%|███████████████████████████████████████████████████████████████████████████▊               | 25/30 [10:56<02:09, 25.83s/it]
03/27/2024 10:40:18 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:40:18 - INFO - trainer -     Num examples = 1120
03/27/2024 10:40:18 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8061    0.7707    0.7880       205
  positivate     0.9698    0.8599    0.9116       821
     neutral     0.3622    0.7553    0.4897        94

    accuracy                         0.8348      1120
   macro avg     0.7127    0.7953    0.7297      1120
weighted avg     0.8888    0.8348    0.8535      1120

03/27/2024 10:40:19 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:40:19 - INFO - trainer -     eval loss: 1.490292381800412
03/27/2024 10:40:19 - INFO - trainer -     acc = 0.8348214285714286
03/27/2024 10:40:19 - INFO - trainer -     f1 = 0.7297469800266146
03/27/2024 10:40:27 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:40:27 - INFO - trainer -     Num examples = 1120
03/27/2024 10:40:27 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7653    0.8287    0.7958       181
  positivate     0.9753    0.8534    0.9103       832
     neutral     0.4082    0.7477    0.5281       107

    accuracy                         0.8393      1120
   macro avg     0.7162    0.8099    0.7447      1120
weighted avg     0.8872    0.8393    0.8552      1120

03/27/2024 10:40:28 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:40:28 - INFO - trainer -     eval loss: 1.2511034922541253
03/27/2024 10:40:28 - INFO - trainer -     acc = 0.8392857142857143
03/27/2024 10:40:28 - INFO - trainer -     f1 = 0.7446883945688999
Epoch:  87%|██████████████████████████████████████████████████████████████████████████████▊            | 26/30 [11:20<01:41, 25.41s/it]
03/27/2024 10:40:36 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:40:36 - INFO - trainer -     Num examples = 1120
03/27/2024 10:40:36 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7959    0.8000    0.7980       195
  positivate     0.9574    0.8756    0.9147       796
     neutral     0.4898    0.7442    0.5908       129

    accuracy                         0.8473      1120
   macro avg     0.7477    0.8066    0.7678      1120
weighted avg     0.8754    0.8473    0.8571      1120

03/27/2024 10:40:38 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:40:38 - INFO - trainer -     eval loss: 1.2105926782358438
03/27/2024 10:40:38 - INFO - trainer -     acc = 0.8473214285714286
03/27/2024 10:40:38 - INFO - trainer -     f1 = 0.7678071192310876
03/27/2024 10:40:45 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:40:45 - INFO - trainer -     Num examples = 1120
03/27/2024 10:40:45 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7653    0.8427    0.8021       178
  positivate     0.9588    0.8926    0.9245       782
     neutral     0.5918    0.7250    0.6517       160

    accuracy                         0.8607      1120
   macro avg     0.7720    0.8201    0.7928      1120
weighted avg     0.8756    0.8607    0.8661      1120

03/27/2024 10:40:47 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:40:47 - INFO - trainer -     eval loss: 1.0039425900189338
03/27/2024 10:40:47 - INFO - trainer -     acc = 0.8607142857142858
03/27/2024 10:40:47 - INFO - trainer -     f1 = 0.7927759139832867
03/27/2024 10:40:55 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:40:55 - INFO - trainer -     Num examples = 1120
03/27/2024 10:40:55 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7857    0.8148    0.8000       189
  positivate     0.9464    0.8971    0.9211       768
     neutral     0.5918    0.7117    0.6462       163

    accuracy                         0.8562      1120
   macro avg     0.7747    0.8079    0.7891      1120
weighted avg     0.8677    0.8562    0.8607      1120

03/27/2024 10:40:56 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:40:56 - INFO - trainer -     eval loss: 1.0778948454768398
03/27/2024 10:40:56 - INFO - trainer -     acc = 0.85625
03/27/2024 10:40:56 - INFO - trainer -     f1 = 0.7891208496566517
Epoch:  90%|█████████████████████████████████████████████████████████████████████████████████▉         | 27/30 [11:46<01:16, 25.61s/it]
03/27/2024 10:41:04 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:41:04 - INFO - trainer -     Num examples = 1120
03/27/2024 10:41:04 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8163    0.7373    0.7748       217
  positivate     0.9258    0.8987    0.9120       750
     neutral     0.5714    0.7320    0.6418       153

    accuracy                         0.8446      1120
   macro avg     0.7712    0.7893    0.7762      1120
weighted avg     0.8562    0.8446    0.8485      1120

03/27/2024 10:41:06 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:41:06 - INFO - trainer -     eval loss: 1.0570878346325896
03/27/2024 10:41:06 - INFO - trainer -     acc = 0.8446428571428571
03/27/2024 10:41:06 - INFO - trainer -     f1 = 0.7762318381948107
03/27/2024 10:41:13 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:41:13 - INFO - trainer -     Num examples = 1120
03/27/2024 10:41:13 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7500    0.8258    0.7861       178
  positivate     0.9657    0.8733    0.9172       805
     neutral     0.5255    0.7518    0.6186       137

    accuracy                         0.8509      1120
   macro avg     0.7471    0.8170    0.7740      1120
weighted avg     0.8775    0.8509    0.8598      1120

03/27/2024 10:41:15 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:41:15 - INFO - trainer -     eval loss: 1.1161296841098063
03/27/2024 10:41:15 - INFO - trainer -     acc = 0.8508928571428571
03/27/2024 10:41:15 - INFO - trainer -     f1 = 0.7739569262534612
03/27/2024 10:41:23 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:41:23 - INFO - trainer -     Num examples = 1120
03/27/2024 10:41:23 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7449    0.8343    0.7871       175
  positivate     0.9547    0.8720    0.9115       797
     neutral     0.5612    0.7432    0.6395       148

    accuracy                         0.8491      1120
   macro avg     0.7536    0.8165    0.7794      1120
weighted avg     0.8699    0.8491    0.8561      1120

03/27/2024 10:41:24 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:41:24 - INFO - trainer -     eval loss: 1.1993670323518537
03/27/2024 10:41:24 - INFO - trainer -     acc = 0.8491071428571428
03/27/2024 10:41:24 - INFO - trainer -     f1 = 0.7793574293887201
Epoch:  93%|████████████████████████████████████████████████████████████████████████████████████▉      | 28/30 [12:12<00:51, 25.67s/it]
03/27/2024 10:41:32 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:41:32 - INFO - trainer -     Num examples = 1120
03/27/2024 10:41:32 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7653    0.8108    0.7874       185
  positivate     0.9519    0.8717    0.9100       795
     neutral     0.5306    0.7429    0.6190       140

    accuracy                         0.8455      1120
   macro avg     0.7493    0.8085    0.7722      1120
weighted avg     0.8684    0.8455    0.8534      1120

03/27/2024 10:41:33 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:41:33 - INFO - trainer -     eval loss: 1.283570124592682
03/27/2024 10:41:33 - INFO - trainer -     acc = 0.8455357142857143
03/27/2024 10:41:33 - INFO - trainer -     f1 = 0.7721650519226791
03/27/2024 10:41:41 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:41:41 - INFO - trainer -     Num examples = 1120
03/27/2024 10:41:41 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8112    0.8071    0.8092       197
  positivate     0.9245    0.9009    0.9125       747
     neutral     0.6020    0.6705    0.6344       176

    accuracy                         0.8482      1120
   macro avg     0.7792    0.7928    0.7854      1120
weighted avg     0.8539    0.8482    0.8507      1120

03/27/2024 10:41:42 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:41:42 - INFO - trainer -     eval loss: 1.1983414469020708
03/27/2024 10:41:42 - INFO - trainer -     acc = 0.8482142857142857
03/27/2024 10:41:42 - INFO - trainer -     f1 = 0.7853704267918017
03/27/2024 10:41:50 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:41:50 - INFO - trainer -     Num examples = 1120
03/27/2024 10:41:50 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8622    0.7191    0.7842       235
  positivate     0.9492    0.8605    0.9027       803
     neutral     0.3367    0.8049    0.4748        82

    accuracy                         0.8268      1120
   macro avg     0.7161    0.7949    0.7206      1120
weighted avg     0.8861    0.8268    0.8465      1120

03/27/2024 10:41:52 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:41:52 - INFO - trainer -     eval loss: 1.2984602566608894
03/27/2024 10:41:52 - INFO - trainer -     acc = 0.8267857142857142
03/27/2024 10:41:52 - INFO - trainer -     f1 = 0.720573623315632
Epoch:  97%|███████████████████████████████████████████████████████████████████████████████████████▉   | 29/30 [12:38<00:25, 25.71s/it]
03/27/2024 10:41:59 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:41:59 - INFO - trainer -     Num examples = 1120
03/27/2024 10:41:59 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.7245    0.7845    0.7533       181
  positivate     0.9753    0.8363    0.9004       849
     neutral     0.3776    0.8222    0.5175        90

    accuracy                         0.8268      1120
   macro avg     0.6924    0.8143    0.7237      1120
weighted avg     0.8867    0.8268    0.8459      1120

03/27/2024 10:42:01 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:42:01 - INFO - trainer -     eval loss: 1.5454368330126662
03/27/2024 10:42:01 - INFO - trainer -     acc = 0.8267857142857142
03/27/2024 10:42:01 - INFO - trainer -     f1 = 0.7237473493787315
03/27/2024 10:42:09 - INFO - trainer -   ***** Running evaluation *****
03/27/2024 10:42:09 - INFO - trainer -     Num examples = 1120
03/27/2024 10:42:09 - INFO - trainer -     Batch size = 32
              precision    recall  f1-score   support

  negativate     0.8214    0.7970    0.8090       202
  positivate     0.9409    0.8919    0.9158       768
     neutral     0.5714    0.7467    0.6474       150

    accuracy                         0.8554      1120
   macro avg     0.7779    0.8119    0.7907      1120
weighted avg     0.8699    0.8554    0.8606      1120

03/27/2024 10:42:10 - INFO - trainer -   ***** Eval results *****
03/27/2024 10:42:10 - INFO - trainer -     eval loss: 0.9790713971173058
03/27/2024 10:42:10 - INFO - trainer -     acc = 0.8553571428571428
03/27/2024 10:42:10 - INFO - trainer -     f1 = 0.7907398237102693
Epoch: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 30/30 [13:02<00:00, 26.09s/it]
03/27/2024 10:42:16 - INFO - __main__ -     acc = 0.8642857142857143
03/27/2024 10:42:16 - INFO - __main__ -     f1 = 0.8011829949413855
(base) lishengping@apple:/nas2/lishengping/caiyun_projects/rgat_absa$ tmux capture-pane -S -32768

